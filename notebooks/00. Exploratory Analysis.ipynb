{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"00. Exploratory Analysis.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dq9AiBOhhjFc"},"source":["> **EXPLORATORY ANALYSIS**\r\n",">\r\n","> ---\r\n",">\r\n","> This notebook is aimed at investigating the structure and the issues regarding the dataset itself. All the code that is exposed here will be then included in the form of utility functions inside [this repository](https://github.com/giuluck/Gangster-SQuAD), so that in the following notebooks, models could be trained directly on the correct data.\r\n","> \r\n","> This is to be considered as the initial notebook in which the methodology of our work is explained. The following notebooks, instead, will be devoted to implementing, training, and evaluating different neural models (one model per notebook) to tackle the *Question-Answering Task*, thus they will all have similar structure."]},{"cell_type":"markdown","metadata":{"id":"DgAW3FJSaiZ6"},"source":["# **0. Retrieve Data**\r\n","\r\n","The raw dataset is retrieved from our public github repository."]},{"cell_type":"code","metadata":{"id":"p_fTKyb3S8_7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610137087635,"user_tz":-60,"elapsed":1856,"user":{"displayName":"Luca Giuliani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe3b5w2A3KfJdjz-DcdAi2-XnwoAlQ0qo0GDTLyW8=s64","userId":"17994520247536922802"}},"outputId":"7f3dfdf5-389c-4f52-f9b5-c64ad286d332"},"source":["!wget https://raw.githubusercontent.com/giuluck/Gangster-SQuAD/main/data/training_set.json"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2021-01-08 20:18:04--  https://raw.githubusercontent.com/giuluck/Gangster-SQuAD/main/data/training_set.json\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 30288272 (29M) [text/plain]\n","Saving to: ‘training_set.json’\n","\n","training_set.json   100%[===================>]  28.88M  72.9MB/s    in 0.4s    \n","\n","2021-01-08 20:18:05 (72.9 MB/s) - ‘training_set.json’ saved [30288272/30288272]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZqXQc8_Na9Uk"},"source":["# **1. Dataset Inspection**\r\n","\r\n","The dataset has a nested structure of lists of dictionaries:\r\n","\r\n","1. The first level has two fields: `data` and `version`. We discard the latter and iterate over the former, which is a list of **442 objects**.\r\n","\r\n","2. The `data` level contains a `title` and a list of `paragraphs`. The `title` will not be useful for the question-answering task but it will be used to split between train and test set (indeed, we want to keep paragraphs regarding the same contexts in the same set), thus we keep it.\r\n","\r\n","3. The `paragraphs` level contains a `context` (the paragraph itself) and a list `qas` of questions and their related answer. The `context` is the string that must be analysed in order to retrieve the answer, which is identified by a span in the text, so it must be kept.\r\n","\r\n","4. The `qas` level contains a `question`, which must be kept in order to be paired with the `context` as the input of the model, an `id` of the question itself, which must be kept because the system is required to pair each answer to the specific id, and a list of `answers`.\r\n","\r\n","5. The `answers` level actually contains one element only. This element is made up of the answer's `text` and an `answer_start` field which identifies at which character the answer starts. This value, then, must be change accordingly in order to identify the correct token and not the character, and must be paired as well with an `end_token` index, which can be retrieved from the length of the answer."]},{"cell_type":"code","metadata":{"id":"MjaKBCVqe4nq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610137088552,"user_tz":-60,"elapsed":2746,"user":{"displayName":"Luca Giuliani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe3b5w2A3KfJdjz-DcdAi2-XnwoAlQ0qo0GDTLyW8=s64","userId":"17994520247536922802"}},"outputId":"94f5dd93-5ecb-43fb-ea0a-ba5cac9228d3"},"source":["import json\r\n","\r\n","def explore_level(level, key, tab=0):\r\n","  # general information\r\n","  print(f'{\"  \" * tab}{tab}. {key}', end=' ')\r\n","\r\n","  # type related information\r\n","  if type(level) == list:\r\n","    print(f\"<class 'list', {len(level)} objects>:\")\r\n","    level = level[0]\r\n","  elif type(level) == dict:\r\n","    print(\"<class 'dict'>:\")\r\n","  else:\r\n","    print(f'--> {type(level)}')\r\n","    return\r\n","  \r\n","  # if not returned explores next level\r\n","  for key, value in level.items():\r\n","    explore_level(value, key, tab + 1)\r\n","\r\n","with open('training_set.json', 'r') as f:\r\n","  dataset = json.load(f)\r\n","\r\n","explore_level(dataset, 'dataset')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["0. dataset <class 'dict'>:\n","  1. data <class 'list', 442 objects>:\n","    2. title --> <class 'str'>\n","    2. paragraphs <class 'list', 55 objects>:\n","      3. context --> <class 'str'>\n","      3. qas <class 'list', 5 objects>:\n","        4. answers <class 'list', 1 objects>:\n","          5. answer_start --> <class 'int'>\n","          5. text --> <class 'str'>\n","        4. question --> <class 'str'>\n","        4. id --> <class 'str'>\n","  1. version --> <class 'str'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8-dGlIoqbPYL","colab":{"base_uri":"https://localhost:8080/","height":597},"executionInfo":{"status":"ok","timestamp":1610137089095,"user_tz":-60,"elapsed":3259,"user":{"displayName":"Luca Giuliani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe3b5w2A3KfJdjz-DcdAi2-XnwoAlQ0qo0GDTLyW8=s64","userId":"17994520247536922802"}},"outputId":"5d2a1f88-3952-49f4-89ce-69eef52836f5"},"source":["import pandas as pd\r\n","\r\n","samples = []\r\n","for data in dataset['data']:\r\n","  title = data['title']\r\n","  for i, paragraph in enumerate(data['paragraphs']):\r\n","    context = paragraph['context']\r\n","    for j, qas in enumerate(paragraph['qas']):\r\n","      id = qas['id']\r\n","      question = qas['question']\r\n","      assert len(qas['answers']) == 1, f'Paragraph {i}, question {j} has {len(qas[\"answers\"])} answers'\r\n","      answer = qas['answers'][0]['text']\r\n","      start = qas['answers'][0]['answer_start']\r\n","      samples.append([id, title, context, question, answer, start])\r\n","\r\n","df = pd.DataFrame(samples, columns=['id', 'title', 'context', 'question', 'answer', 'start'])\r\n","df"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>context</th>\n","      <th>question</th>\n","      <th>answer</th>\n","      <th>start</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5733be284776f41900661182</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>To whom did the Virgin Mary allegedly appear i...</td>\n","      <td>Saint Bernadette Soubirous</td>\n","      <td>515</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5733be284776f4190066117f</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What is in front of the Notre Dame Main Building?</td>\n","      <td>a copper statue of Christ</td>\n","      <td>188</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5733be284776f41900661180</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n","      <td>the Main Building</td>\n","      <td>279</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5733be284776f41900661181</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What is the Grotto at Notre Dame?</td>\n","      <td>a Marian place of prayer and reflection</td>\n","      <td>381</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5733be284776f4190066117e</td>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","      <td>What sits on top of the Main Building at Notre...</td>\n","      <td>a golden statue of the Virgin Mary</td>\n","      <td>92</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>87594</th>\n","      <td>5735d259012e2f140011a09d</td>\n","      <td>Kathmandu</td>\n","      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n","      <td>In what US state did Kathmandu first establish...</td>\n","      <td>Oregon</td>\n","      <td>229</td>\n","    </tr>\n","    <tr>\n","      <th>87595</th>\n","      <td>5735d259012e2f140011a09e</td>\n","      <td>Kathmandu</td>\n","      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n","      <td>What was Yangon previously known as?</td>\n","      <td>Rangoon</td>\n","      <td>414</td>\n","    </tr>\n","    <tr>\n","      <th>87596</th>\n","      <td>5735d259012e2f140011a09f</td>\n","      <td>Kathmandu</td>\n","      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n","      <td>With what Belorussian city does Kathmandu have...</td>\n","      <td>Minsk</td>\n","      <td>476</td>\n","    </tr>\n","    <tr>\n","      <th>87597</th>\n","      <td>5735d259012e2f140011a0a0</td>\n","      <td>Kathmandu</td>\n","      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n","      <td>In what year did Kathmandu create its initial ...</td>\n","      <td>1975</td>\n","      <td>199</td>\n","    </tr>\n","    <tr>\n","      <th>87598</th>\n","      <td>5735d259012e2f140011a0a1</td>\n","      <td>Kathmandu</td>\n","      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n","      <td>What is KMC an initialism of?</td>\n","      <td>Kathmandu Metropolitan City</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>87599 rows × 6 columns</p>\n","</div>"],"text/plain":["                             id  ... start\n","0      5733be284776f41900661182  ...   515\n","1      5733be284776f4190066117f  ...   188\n","2      5733be284776f41900661180  ...   279\n","3      5733be284776f41900661181  ...   381\n","4      5733be284776f4190066117e  ...    92\n","...                         ...  ...   ...\n","87594  5735d259012e2f140011a09d  ...   229\n","87595  5735d259012e2f140011a09e  ...   414\n","87596  5735d259012e2f140011a09f  ...   476\n","87597  5735d259012e2f140011a0a0  ...   199\n","87598  5735d259012e2f140011a0a1  ...     0\n","\n","[87599 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"ik_VFH1gCq2v"},"source":["### ***1.1. Records Cleaning***\r\n","\r\n","- Some questions are **not properly defined**, e.g., they do not have a question mark. Still, this should not be a problem so, given that there are a bunch of them, we keep them.\r\n","\r\n","- Some questions, however, do not have any meaning and they represent fake records, thus they must be excluded. This does not occurr for the contexts."]},{"cell_type":"code","metadata":{"id":"g4nK3_3xbYQs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610137089097,"user_tz":-60,"elapsed":3247,"user":{"displayName":"Luca Giuliani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe3b5w2A3KfJdjz-DcdAi2-XnwoAlQ0qo0GDTLyW8=s64","userId":"17994520247536922802"}},"outputId":"6229a3fd-f23c-4711-da07-7ee7b64e4a55"},"source":["poorly_defined_questions = [q for q in df['question'] if '?' not in q]\r\n","len(poorly_defined_questions)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["949"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"RGrVEjASlBEW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610137089099,"user_tz":-60,"elapsed":3238,"user":{"displayName":"Luca Giuliani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe3b5w2A3KfJdjz-DcdAi2-XnwoAlQ0qo0GDTLyW8=s64","userId":"17994520247536922802"}},"outputId":"e0c08c2f-2997-419a-ec9d-ff89a647815e"},"source":["excluded_questions = [q for q in df['question'] if len(q) < 10]\r\n","print('Questions:', excluded_questions)\r\n","\r\n","excluded_contexts = [c for c in df['context'] if len(c) < 10]\r\n","print('Contexts: ', excluded_contexts)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Questions: ['k', 'j', 'n', 'b', 'v', 'dd', 'dd', 'dd', 'dd', 'd']\n","Contexts:  []\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nMGfzNL1lNX5","colab":{"base_uri":"https://localhost:8080/","height":551},"executionInfo":{"status":"ok","timestamp":1610137089101,"user_tz":-60,"elapsed":3224,"user":{"displayName":"Luca Giuliani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe3b5w2A3KfJdjz-DcdAi2-XnwoAlQ0qo0GDTLyW8=s64","userId":"17994520247536922802"}},"outputId":"7b37b76c-f875-4a43-8d6c-d23f56889ea0"},"source":["excluded_questions += [\"I couldn't could up with another question. But i need to fill this space because I can't submit the hit. \"]\r\n","excluded_questions = set(excluded_questions)\r\n","\r\n","df[df['question'].isin(excluded_questions)][['question', 'answer']]"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>16818</th>\n","      <td>k</td>\n","      <td>ks</td>\n","    </tr>\n","    <tr>\n","      <th>16819</th>\n","      <td>j</td>\n","      <td>Ch</td>\n","    </tr>\n","    <tr>\n","      <th>16820</th>\n","      <td>n</td>\n","      <td>n</td>\n","    </tr>\n","    <tr>\n","      <th>16821</th>\n","      <td>b</td>\n","      <td>b</td>\n","    </tr>\n","    <tr>\n","      <th>16822</th>\n","      <td>v</td>\n","      <td>v</td>\n","    </tr>\n","    <tr>\n","      <th>38422</th>\n","      <td>dd</td>\n","      <td>yptian Se</td>\n","    </tr>\n","    <tr>\n","      <th>38423</th>\n","      <td>dd</td>\n","      <td>Buddh</td>\n","    </tr>\n","    <tr>\n","      <th>38424</th>\n","      <td>dd</td>\n","      <td>m and E</td>\n","    </tr>\n","    <tr>\n","      <th>38425</th>\n","      <td>dd</td>\n","      <td>Buddhism</td>\n","    </tr>\n","    <tr>\n","      <th>38426</th>\n","      <td>d</td>\n","      <td>the Gre</td>\n","    </tr>\n","    <tr>\n","      <th>38466</th>\n","      <td>I couldn't could up with another question. But...</td>\n","      <td>moved</td>\n","    </tr>\n","    <tr>\n","      <th>38536</th>\n","      <td>I couldn't could up with another question. But...</td>\n","      <td>refor</td>\n","    </tr>\n","    <tr>\n","      <th>38546</th>\n","      <td>I couldn't could up with another question. But...</td>\n","      <td>tes (3</td>\n","    </tr>\n","    <tr>\n","      <th>38676</th>\n","      <td>I couldn't could up with another question. But...</td>\n","      <td>y of</td>\n","    </tr>\n","    <tr>\n","      <th>38704</th>\n","      <td>I couldn't could up with another question. But...</td>\n","      <td>dom. The resulting Indo-Scythian kingdom seems...</td>\n","    </tr>\n","    <tr>\n","      <th>38705</th>\n","      <td>I couldn't could up with another question. But...</td>\n","      <td>in</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                question                                             answer\n","16818                                                  k                                                 ks\n","16819                                                  j                                                 Ch\n","16820                                                  n                                                  n\n","16821                                                  b                                                  b\n","16822                                                  v                                                  v\n","38422                                                 dd                                          yptian Se\n","38423                                                 dd                                              Buddh\n","38424                                                 dd                                            m and E\n","38425                                                 dd                                           Buddhism\n","38426                                                  d                                            the Gre\n","38466  I couldn't could up with another question. But...                                              moved\n","38536  I couldn't could up with another question. But...                                              refor\n","38546  I couldn't could up with another question. But...                                             tes (3\n","38676  I couldn't could up with another question. But...                                               y of\n","38704  I couldn't could up with another question. But...  dom. The resulting Indo-Scythian kingdom seems...\n","38705  I couldn't could up with another question. But...                                                 in"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"0oUrNcS_E38W"},"source":["### ***1.2. Final Dataset***\r\n","\r\n","We only keep the records with correct questions."]},{"cell_type":"code","metadata":{"id":"xtL43MNSlTFk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610137089102,"user_tz":-60,"elapsed":3216,"user":{"displayName":"Luca Giuliani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe3b5w2A3KfJdjz-DcdAi2-XnwoAlQ0qo0GDTLyW8=s64","userId":"17994520247536922802"}},"outputId":"6800ffb5-c50e-45f7-dfe8-ec71be62858c"},"source":["df = df[~df['question'].isin(excluded_questions)]\r\n","print(len(df), 'records remained')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["87583 records remained\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sVOvbVMMWE-e"},"source":["# **2. Train-Val-Test Splits**\r\n","\r\n","We will now slice the dataset into a ***train***, a ***validation***, and a ***test*** split. The ***train*** and the ***validation*** splits will be used in the following notebooks to train the models and to evaluate their performance, respectively. Once each model is trained, just the one that gave the best results will be evaluated on the ***test*** set, and that will be considered our final performance on the task.\r\n","\r\n","To split the dataset into *train*, *val* and *test* splits, we rely on the `title` attribute of the original data. This is done to avoid that records in two different splits share the same subject, so that a total independence from the data in the three splits is guaranteed. In order to do that, we retrieve the `split_title` which is in a certain index, then we split the dataset so that each record with that or a subsequent title is part of one split, while records with the other titles are part of the other split."]},{"cell_type":"markdown","metadata":{"id":"cUJw0nu2uNRJ"},"source":["### ***3.1. Train-Val-Test Split***\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z4bywBhNWwLG","executionInfo":{"status":"ok","timestamp":1610137089104,"user_tz":-60,"elapsed":3208,"user":{"displayName":"Luca Giuliani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe3b5w2A3KfJdjz-DcdAi2-XnwoAlQ0qo0GDTLyW8=s64","userId":"17994520247536922802"}},"outputId":"4290abc5-58de-4646-ba4b-eafbaa5e32ab"},"source":["def title_based_split(data, split_val=0.7):\r\n","  # retrieve split title and get the minimum id with that title\r\n","  split_title = data['title'].iloc[int(split_val * len(data))]\r\n","  split_index = data[data['title'] == split_title].index.min()\r\n","  return data.iloc[:split_index], data.iloc[split_index:]\r\n","\r\n","train_df, test_df = title_based_split(df)\r\n","print('Train-Test Split:', len(train_df) / len(df))\r\n","\r\n","train_df, val_df = title_based_split(train_df)\r\n","print('Train-Val Split:', len(train_df) / (len(train_df) + len(val_df)))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Train-Test Split: 0.6994964776269368\n","Train-Val Split: 0.6983056933925307\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"z2wzMGcZWl5o","executionInfo":{"status":"ok","timestamp":1610137089105,"user_tz":-60,"elapsed":3193,"user":{"displayName":"Luca Giuliani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe3b5w2A3KfJdjz-DcdAi2-XnwoAlQ0qo0GDTLyW8=s64","userId":"17994520247536922802"}},"outputId":"b63f2f53-2d8a-4a24-8a13-7ec255df5dba"},"source":["train_df[['title', 'context']]"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>context</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>University_of_Notre_Dame</td>\n","      <td>Architecturally, the school has a Catholic cha...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>42792</th>\n","      <td>Southeast_Asia</td>\n","      <td>The Andaman and Nicobar Islands of India are g...</td>\n","    </tr>\n","    <tr>\n","      <th>42793</th>\n","      <td>Southeast_Asia</td>\n","      <td>The Andaman and Nicobar Islands of India are g...</td>\n","    </tr>\n","    <tr>\n","      <th>42794</th>\n","      <td>Southeast_Asia</td>\n","      <td>The Andaman and Nicobar Islands of India are g...</td>\n","    </tr>\n","    <tr>\n","      <th>42795</th>\n","      <td>Southeast_Asia</td>\n","      <td>The Andaman and Nicobar Islands of India are g...</td>\n","    </tr>\n","    <tr>\n","      <th>42796</th>\n","      <td>Southeast_Asia</td>\n","      <td>The Andaman and Nicobar Islands of India are g...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>42781 rows × 2 columns</p>\n","</div>"],"text/plain":["                          title                                            context\n","0      University_of_Notre_Dame  Architecturally, the school has a Catholic cha...\n","1      University_of_Notre_Dame  Architecturally, the school has a Catholic cha...\n","2      University_of_Notre_Dame  Architecturally, the school has a Catholic cha...\n","3      University_of_Notre_Dame  Architecturally, the school has a Catholic cha...\n","4      University_of_Notre_Dame  Architecturally, the school has a Catholic cha...\n","...                         ...                                                ...\n","42792            Southeast_Asia  The Andaman and Nicobar Islands of India are g...\n","42793            Southeast_Asia  The Andaman and Nicobar Islands of India are g...\n","42794            Southeast_Asia  The Andaman and Nicobar Islands of India are g...\n","42795            Southeast_Asia  The Andaman and Nicobar Islands of India are g...\n","42796            Southeast_Asia  The Andaman and Nicobar Islands of India are g...\n","\n","[42781 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"VLbqlQ95Xy4X","executionInfo":{"status":"ok","timestamp":1610137089108,"user_tz":-60,"elapsed":3179,"user":{"displayName":"Luca Giuliani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe3b5w2A3KfJdjz-DcdAi2-XnwoAlQ0qo0GDTLyW8=s64","userId":"17994520247536922802"}},"outputId":"7cd743c0-0f31-429b-878d-de0b1f2517c9"},"source":["val_df[['title', 'context']]"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>context</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>42797</th>\n","      <td>Southeast_Asia</td>\n","      <td>Homo sapiens reached the region by around 45,0...</td>\n","    </tr>\n","    <tr>\n","      <th>42798</th>\n","      <td>Southeast_Asia</td>\n","      <td>Homo sapiens reached the region by around 45,0...</td>\n","    </tr>\n","    <tr>\n","      <th>42799</th>\n","      <td>Southeast_Asia</td>\n","      <td>Homo sapiens reached the region by around 45,0...</td>\n","    </tr>\n","    <tr>\n","      <th>42800</th>\n","      <td>Southeast_Asia</td>\n","      <td>Homo sapiens reached the region by around 45,0...</td>\n","    </tr>\n","    <tr>\n","      <th>42801</th>\n","      <td>Southeast_Asia</td>\n","      <td>Homo sapiens reached the region by around 45,0...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>61275</th>\n","      <td>Gamal_Abdel_Nasser</td>\n","      <td>Nasser remains an iconic figure in the Arab wo...</td>\n","    </tr>\n","    <tr>\n","      <th>61276</th>\n","      <td>Gamal_Abdel_Nasser</td>\n","      <td>Nasser remains an iconic figure in the Arab wo...</td>\n","    </tr>\n","    <tr>\n","      <th>61277</th>\n","      <td>Gamal_Abdel_Nasser</td>\n","      <td>Nasser remains an iconic figure in the Arab wo...</td>\n","    </tr>\n","    <tr>\n","      <th>61278</th>\n","      <td>Gamal_Abdel_Nasser</td>\n","      <td>Gamal Abdel Nasser was born on 15 January 1918...</td>\n","    </tr>\n","    <tr>\n","      <th>61279</th>\n","      <td>Gamal_Abdel_Nasser</td>\n","      <td>Gamal Abdel Nasser was born on 15 January 1918...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>18483 rows × 2 columns</p>\n","</div>"],"text/plain":["                    title                                            context\n","42797      Southeast_Asia  Homo sapiens reached the region by around 45,0...\n","42798      Southeast_Asia  Homo sapiens reached the region by around 45,0...\n","42799      Southeast_Asia  Homo sapiens reached the region by around 45,0...\n","42800      Southeast_Asia  Homo sapiens reached the region by around 45,0...\n","42801      Southeast_Asia  Homo sapiens reached the region by around 45,0...\n","...                   ...                                                ...\n","61275  Gamal_Abdel_Nasser  Nasser remains an iconic figure in the Arab wo...\n","61276  Gamal_Abdel_Nasser  Nasser remains an iconic figure in the Arab wo...\n","61277  Gamal_Abdel_Nasser  Nasser remains an iconic figure in the Arab wo...\n","61278  Gamal_Abdel_Nasser  Gamal Abdel Nasser was born on 15 January 1918...\n","61279  Gamal_Abdel_Nasser  Gamal Abdel Nasser was born on 15 January 1918...\n","\n","[18483 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"katRFzV7dlNk","executionInfo":{"status":"ok","timestamp":1610137089111,"user_tz":-60,"elapsed":3161,"user":{"displayName":"Luca Giuliani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghe3b5w2A3KfJdjz-DcdAi2-XnwoAlQ0qo0GDTLyW8=s64","userId":"17994520247536922802"}},"outputId":"f7cbf730-2f11-41b8-d506-a5f07afab25c"},"source":["test_df[['title', 'context']]"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>context</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>61280</th>\n","      <td>Gamal_Abdel_Nasser</td>\n","      <td>Gamal Abdel Nasser was born on 15 January 1918...</td>\n","    </tr>\n","    <tr>\n","      <th>61281</th>\n","      <td>Gamal_Abdel_Nasser</td>\n","      <td>Gamal Abdel Nasser was born on 15 January 1918...</td>\n","    </tr>\n","    <tr>\n","      <th>61282</th>\n","      <td>Gamal_Abdel_Nasser</td>\n","      <td>Gamal Abdel Nasser was born on 15 January 1918...</td>\n","    </tr>\n","    <tr>\n","      <th>61283</th>\n","      <td>Gamal_Abdel_Nasser</td>\n","      <td>In 1928, Nasser went to Alexandria to live wit...</td>\n","    </tr>\n","    <tr>\n","      <th>61284</th>\n","      <td>Gamal_Abdel_Nasser</td>\n","      <td>In 1928, Nasser went to Alexandria to live wit...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>87594</th>\n","      <td>Kathmandu</td>\n","      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n","    </tr>\n","    <tr>\n","      <th>87595</th>\n","      <td>Kathmandu</td>\n","      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n","    </tr>\n","    <tr>\n","      <th>87596</th>\n","      <td>Kathmandu</td>\n","      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n","    </tr>\n","    <tr>\n","      <th>87597</th>\n","      <td>Kathmandu</td>\n","      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n","    </tr>\n","    <tr>\n","      <th>87598</th>\n","      <td>Kathmandu</td>\n","      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>26319 rows × 2 columns</p>\n","</div>"],"text/plain":["                    title                                            context\n","61280  Gamal_Abdel_Nasser  Gamal Abdel Nasser was born on 15 January 1918...\n","61281  Gamal_Abdel_Nasser  Gamal Abdel Nasser was born on 15 January 1918...\n","61282  Gamal_Abdel_Nasser  Gamal Abdel Nasser was born on 15 January 1918...\n","61283  Gamal_Abdel_Nasser  In 1928, Nasser went to Alexandria to live wit...\n","61284  Gamal_Abdel_Nasser  In 1928, Nasser went to Alexandria to live wit...\n","...                   ...                                                ...\n","87594           Kathmandu  Kathmandu Metropolitan City (KMC), in order to...\n","87595           Kathmandu  Kathmandu Metropolitan City (KMC), in order to...\n","87596           Kathmandu  Kathmandu Metropolitan City (KMC), in order to...\n","87597           Kathmandu  Kathmandu Metropolitan City (KMC), in order to...\n","87598           Kathmandu  Kathmandu Metropolitan City (KMC), in order to...\n","\n","[26319 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"sHD2aAmOph0J"},"source":[""],"execution_count":null,"outputs":[]}]}